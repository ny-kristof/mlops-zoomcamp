{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26913da1-8f99-4cef-947f-63916d618c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import pickle\n",
    "SAMPLE_FRAC = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6fe8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefer pyarrow for all parquet IO in pandas\n",
    "import pandas as pd\n",
    "pd.options.io.parquet.engine = 'pyarrow'  # affects read_parquet/to_parquet defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d0f3e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5323084a-aea0-4974-a166-c2c7cf30eb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca47bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 16:09:59 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/10/18 16:09:59 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025/10/18 16:09:59 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Experiment: artifact_location='/workspaces/mlops-zoomcamp/02-experiment-tracking/mlruns/1', creation_time=1760793866099, experiment_id='1', last_update_time=1760793866099, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "\n",
    "print(mlflow.get_experiment_by_name(\"nyc-taxi-experiment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b953361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_dataframe(filename):\n",
    "#     df = pd.read_parquet(filename, engine='pyarrow')\n",
    "    \n",
    "#     df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "#     df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "#     df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "#     df.duration = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "#     df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    \n",
    "#     categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "#     df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "def read_dataframe(filename: str, sample_frac: float | None = None) -> pd.DataFrame:\n",
    "    # Read only necessary columns to reduce memory\n",
    "    cols = [\n",
    "        'lpep_dropoff_datetime', 'lpep_pickup_datetime',\n",
    "        'PULocationID', 'DOLocationID', 'trip_distance'\n",
    "    ]\n",
    "    print(f\"Reading parquet from {filename} with pyarrow and columns={cols} ...\", flush=True)\n",
    "    df = pd.read_parquet(filename, engine='pyarrow', columns=cols)\n",
    "\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    if sample_frac is not None and 0 < sample_frac < 1:\n",
    "        df = df.sample(frac=sample_frac, random_state=42).reset_index(drop=True)\n",
    "        print(f\"Sampled dataframe to frac={sample_frac}: shape={df.shape}\")\n",
    "    else:\n",
    "        print(f\"Loaded dataframe shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9c37570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet with pyarrow and columns=['lpep_dropoff_datetime', 'lpep_pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_distance'] ...\n",
      "Sampled dataframe to frac=0.3: shape=(22172, 6)\n",
      "Reading parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet with pyarrow and columns=['lpep_dropoff_datetime', 'lpep_pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_distance'] ...\n",
      "Sampled dataframe to frac=0.3: shape=(22172, 6)\n",
      "Reading parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet with pyarrow and columns=['lpep_dropoff_datetime', 'lpep_pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_distance'] ...\n",
      "Sampled dataframe to frac=0.3: shape=(18576, 6)\n",
      "Sampled dataframe to frac=0.3: shape=(18576, 6)\n"
     ]
    }
   ],
   "source": [
    "df_train = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet', sample_frac = SAMPLE_FRAC)\n",
    "df_val = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet', sample_frac = SAMPLE_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9b8f6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22172, 18576)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a6493e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab8f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] \n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc97aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values \n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f67da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.699564118198954)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = lr.predict(X_train)\n",
    "\n",
    "# root_mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1020f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('models/lin_reg.bin', 'wb') as f_out:\n",
    "#     pickle.dump((dv, lr), f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fda8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mlflow.start_run():\n",
    "\n",
    "#     mlflow.set_tag(\"developer\", \"Kristof\")\n",
    "#     mlflow.log_param(\"train-data-path\", 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet')\n",
    "#     mlflow.log_param(\"valid-data-path\", 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet')\n",
    "\n",
    "#     alpha = 0.01\n",
    "#     mlflow.log_param(\"alpha\", alpha)\n",
    "#     lr = Lasso(alpha=alpha)\n",
    "#     lr.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = lr.predict(X_val)\n",
    "#     rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "#     mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "#     mlflow.log_artifact('models/lin_reg.bin', artifact_path='models_pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238075b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: write a sample parquet with pyarrow and log via MLflow\n",
    "# sample_path = 'models/sample_data.parquet'\n",
    "# df.head(1000).to_parquet(sample_path, engine='pyarrow', index=False)\n",
    "# mlflow.log_artifact(sample_path, artifact_path='datasets')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661b8b74",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3bc31f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/conda-env/lib/python3.12/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "273a9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aca936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        \n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53833ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42\n",
    "    }\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "887d8065",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1473016",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    best_params = {\n",
    "        'max_depth': 48,\n",
    "        'learning_rate': 0.1256073328183555,\n",
    "        'reg_alpha': 0.34485337886791795,\n",
    "        'reg_lambda': 0.018950580168387268,\n",
    "        'min_child_weight': 1.492447195778266,\n",
    "        'objective': 'reg:linear',\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=100,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    with open('models/preprocessor.b', 'wb') as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # Log the XGBoost model with signature\n",
    "    signature = mlflow.models.infer_signature(X_val, y_pred)\n",
    "    \n",
    "    mlflow.xgboost.log_model(\n",
    "        xgb_model=booster, \n",
    "        name=\"MyModel\",\n",
    "        signature=signature\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52e9f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "mlflow.sklearn.autolog(\n",
    "    log_models=True,\n",
    "    log_datasets=True,\n",
    "    log_input_examples=True,\n",
    "    log_model_signatures=True,\n",
    ")\n",
    "\n",
    "for model_class in (RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, LinearSVR):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2021-01.csv\")\n",
    "        mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2021-02.csv\")\n",
    "        mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "        mlmodel = model_class()\n",
    "        mlmodel.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = mlmodel.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
